\from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType, TimestampType
import os

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± SparkSession
spark = SparkSession.builder \
    .appName("CSV to Parquet Local Conversion") \
    .master("local[*]") \
    .getOrCreate()

spark.sparkContext.setLogLevel("ERROR")

# ğŸ”½ Î¤Î¿Ï€Î¹ÎºÏŒ path Ï„Î¿Ï… CSV
csv_file_path = "yellow_tripdata_2024.csv"

# ğŸ”¼ Output path Î³Î¹Î± Ï„Î¿ Parquet
output_path = "parquet_output/yellow_tripdata_2024"

# ğŸ“ Schema Ï„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
schema = StructType([
    StructField("VendorID", IntegerType()),
    StructField("tpep_pickup_datetime", TimestampType()),
    StructField("tpep_dropoff_datetime", TimestampType()),
    StructField("passenger_count", IntegerType()),
    StructField("trip_distance", FloatType()),
    StructField("RatecodeID", IntegerType()),
    StructField("store_and_fwd_flag", StringType()),
    StructField("PULocationID", IntegerType()),
    StructField("DOLocationID", IntegerType()),
    StructField("payment_type", IntegerType()),
    StructField("fare_amount", FloatType()),
    StructField("extra", FloatType()),
    StructField("mta_tax", FloatType()),
    StructField("tip_amount", FloatType()),
    StructField("tolls_amount", FloatType()),
    StructField("improvement_surcharge", FloatType()),
    StructField("total_amount", FloatType()),
    StructField("congestion_surcharge", FloatType()),
    StructField("airport_fee", FloatType())
])

# âœ… Î¦ÏŒÏÏ„Ï‰ÏƒÎ· CSV Î¼Îµ schema
df = spark.read.format("csv") \
    .option("header", "false") \
    .schema(schema) \
    .load(csv_file_path)

# Î ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·
print("ğŸ“Š Î ÏÏÏ„ÎµÏ‚ ÎµÎ³Î³ÏÎ±Ï†Î­Ï‚:")
df.show(5)

# âœ… ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÏƒÎµ Parquet
df.write.mode("overwrite").parquet(output_path)

print(f"âœ… Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Ï‰Ï‚ Parquet ÏƒÏ„Î¿: {output_path}")
